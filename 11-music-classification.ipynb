{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\ngtzan = load_dataset(\"marsyas/gtzan\", \"all\")\ngtzan","metadata":{"execution":{"iopub.status.busy":"2023-08-21T08:15:09.489141Z","iopub.execute_input":"2023-08-21T08:15:09.489869Z","iopub.status.idle":"2023-08-21T08:15:58.388959Z","shell.execute_reply.started":"2023-08-21T08:15:09.489832Z","shell.execute_reply":"2023-08-21T08:15:58.388044Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6b0b78b023746e8977f963f700389b2"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset gtzan/all to /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/8bd0e23c2d9b2be30d36bc6834319772dff22a3bd28527996612386cef003910...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.23G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd1b03ee0654812897a6bde9dc4b428"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset gtzan downloaded and prepared to /root/.cache/huggingface/datasets/marsyas___gtzan/all/0.0.0/8bd0e23c2d9b2be30d36bc6834319772dff22a3bd28527996612386cef003910. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18805fe2f7334f1bbbff2b3c49bb36eb"}},"metadata":{}},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['file', 'audio', 'genre'],\n        num_rows: 999\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"gtzan = gtzan.train_test_split(seed=42, shuffle=True, test_size=0.1)\ngtzan","metadata":{"execution":{"iopub.status.busy":"2023-08-21T08:16:01.882190Z","iopub.execute_input":"2023-08-21T08:16:01.882909Z","iopub.status.idle":"2023-08-21T08:16:02.304842Z","shell.execute_reply.started":"2023-08-21T08:16:01.882870Z","shell.execute_reply":"2023-08-21T08:16:02.303174Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gtzan \u001b[38;5;241m=\u001b[39m \u001b[43mgtzan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      2\u001b[0m gtzan\n","\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'train_test_split'"],"ename":"AttributeError","evalue":"'DatasetDict' object has no attribute 'train_test_split'","output_type":"error"}]},{"cell_type":"code","source":"gtzan[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-21T08:18:46.337538Z","iopub.execute_input":"2023-08-21T08:18:46.337997Z","iopub.status.idle":"2023-08-21T08:18:59.499192Z","shell.execute_reply.started":"2023-08-21T08:18:46.337964Z","shell.execute_reply":"2023-08-21T08:18:59.498313Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'file': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/blues/blues.00000.wav',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/5022b0984afa7334ff9a3c60566280b08b5179d4ac96a628052bada7d8940244/genres/blues/blues.00000.wav',\n  'array': array([ 0.00732422,  0.01660156,  0.00762939, ..., -0.05560303,\n         -0.06106567, -0.06417847], dtype=float32),\n  'sampling_rate': 22050},\n 'genre': 0}"},"metadata":{}}]},{"cell_type":"code","source":"id2label_fn = gtzan[\"train\"].features[\"genre\"].int2str\nid2label_fn(gtzan[\"train\"][0][\"genre\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-21T08:20:50.973900Z","iopub.execute_input":"2023-08-21T08:20:50.975593Z","iopub.status.idle":"2023-08-21T08:20:50.996222Z","shell.execute_reply.started":"2023-08-21T08:20:50.975552Z","shell.execute_reply":"2023-08-21T08:20:50.995302Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'blues'"},"metadata":{}}]},{"cell_type":"code","source":"import gradio as gr\n\n\ndef generate_audio():\n    example = gtzan[\"train\"].shuffle()[0]\n    audio = example[\"audio\"]\n    return (\n        audio[\"sampling_rate\"],\n        audio[\"array\"],\n    ), id2label_fn(example[\"genre\"])\n\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        for _ in range(4):\n            audio, label = generate_audio()\n            output = gr.Audio(audio, label=label)\n\ndemo.launch(debug=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-21T08:23:00.254864Z","iopub.execute_input":"2023-08-21T08:23:00.255363Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gradio/processing_utils.py:183: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n  warnings.warn(warning.format(data.dtype))\n","output_type":"stream"},{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7860\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://a590de3846594c8b06.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://a590de3846594c8b06.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing the data","metadata":{}},{"cell_type":"code","source":"from transformers import AutoFeatureExtractor\n\nmodel_id = \"ntu-spml/distilhubert\"\nfeature_extractor = AutoFeatureExtractor.from_pretrained(\n    model_id, do_normalize=True, return_attention_mask=True\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampling_rate = feature_extractor.sampling_rate\nsampling_rate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Audio\n\ngtzan = gtzan.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nsample = gtzan[\"train\"][0][\"audio\"]\n\nprint(f\"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n\nprint(f\"inputs keys: {list(inputs.keys())}\")\n\nprint(\n    f\"Mean: {np.mean(inputs['input_values']):.3}, Variance: {np.var(inputs['input_values']):.3}\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_duration = 30.0\n\n\ndef preprocess_function(examples):\n    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n    inputs = feature_extractor(\n        audio_arrays,\n        sampling_rate=feature_extractor.sampling_rate,\n        max_length=int(feature_extractor.sampling_rate * max_duration),\n        truncation=True,\n        return_attention_mask=True,\n    )\n    return inputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gtzan_encoded = gtzan.map(\n    preprocess_function,\n    remove_columns=[\"audio\", \"file\"],\n    batched=True,\n    batch_size=100,\n    num_proc=1,\n)\ngtzan_encoded","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gtzan_encoded = gtzan_encoded.rename_column(\"genre\", \"label\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id2label = {\n    str(i): id2label_fn(i)\n    for i in range(len(gtzan_encoded[\"train\"].features[\"label\"].names))\n}\nlabel2id = {v: k for k, v in id2label.items()}\n\nid2label[\"7\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForAudioClassification\n\nnum_labels = len(id2label)\n\nmodel = AutoModelForAudioClassification.from_pretrained(\n    model_id,\n    num_labels=num_labels,\n    label2id=label2id,\n    id2label=id2label,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nmodel_name = model_id.split(\"/\")[-1]\nbatch_size = 8\ngradient_accumulation_steps = 1\nnum_train_epochs = 10\n\ntraining_args = TrainingArguments(\n    f\"{model_name}-finetuned-gtzan\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_train_epochs,\n    warmup_ratio=0.1,\n    logging_steps=5,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nmetric = evaluate.load(\"accuracy\")\n\n\ndef compute_metrics(eval_pred):\n    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n    predictions = np.argmax(eval_pred.predictions, axis=1)\n    return metric.compute(predictions=predictions, references=eval_pred.label_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=gtzan_encoded[\"train\"],\n    eval_dataset=gtzan_encoded[\"test\"],\n    tokenizer=feature_extractor,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kwargs = {\n    \"dataset_tags\": \"marsyas/gtzan\",\n    \"dataset\": \"GTZAN\",\n    \"model_name\": f\"{model_name}-finetuned-gtzan\",\n    \"finetuned_from\": model_id,\n    \"tasks\": \"audio-classification\",\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub(**kwargs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\npipe = pipeline(\n    \"audio-classification\", model=\"sanchit-gandhi/distilhubert-finetuned-gtzan\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}